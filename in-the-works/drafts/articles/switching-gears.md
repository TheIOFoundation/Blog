---
description: The need for a long term vision on changing the technology paradigm.
---

# Switching gears

> _As we become so visible in the digital world and leave an endless trail of data behind us, exactly who has our data and what they do with it becomes increasingly important._
>
> Peter Gabriel

This article was initially published as part of xxx\
[https://digitalrights.ai/report/](https://digitalrights.ai/report/)\
[https://digitalrights.ai/report/case-profiles/](https://digitalrights.ai/report/case-profiles/)\
[https://digitalrights.ai/2022/03/18/switching-gears/](https://digitalrights.ai/2022/03/18/switching-gears/)



A recurring slide in all my presentations presents the face of a man with some fancy-looking painting on his face that transmits a techno-futuristic vibe, accompanied by the caption

“We ~~the people~~ >> We the cyborgs”.

When delivering, I look around the audience and see who giggles or reacts in disbelief and then proceed to invite them to hand me over their phones so as to revisit the idea again in a week’s time.

\


While the degree of adoption may differ, technology has penetrated our lives to the point of no return: it has effectively become a natural extension of our bodies that enable us to interact with our environment just as much as our limbs.

Our currently inefficient interface (vision + touch + voice) is slowly blurring as we progress towards implanted solutions with over 10 companies working on this field alone.

\


Let’s consider this for a second: we are developing invasive hardware in a world where security and privacy are being taught as “Best Practices” instead of a unified standard. As hard as it is to protect citizens from data extractionism via non-grafted devices, how do we expect this to play out moving forward when we have a chip physically linked to our brain? Are we looking at technology through the right lens or instead playing the games of financial interests, ideological agendas and splashing colors that have little to do with its nature and impact?

\


The predominant cognitive dissonance in technology is easy to observe when finding equivalencies in more familiar industries. No “Best Practices” for seat belts in cars: All manufacturers know both the behavioral and technical descriptions of cars per jurisdiction, authorities have means to test compliance and citizens can concentrate on the responsible use of the device.

\


_“Why are we capable of reaching consensus upon products such as cars and not about our digital lives?”_, you may ask. Well, for one because we can easily recognize what happens in case of a bad design: you and others may die. We can’t claim the same understanding for our data and the models they create, otherwise known as digital twins; even less so for the digital harms they may be exposed to.

\


When considering what took us to this point, we simply need to admit that we have been looking at technology wrong and not engaging all the right people.

\


\- First of all, we have a total misunderstanding of the nature of data, which has led to building narratives of extraction and usage that we now start to understand are detrimental in the long run.

\


\- Then we made the mistake to only concentrate on policies that describe what is supposed to happen yet failed in explaining how it is supposed to be built, which in turn has translated into the inability to embed those protections in the tech by design.

\


\- Last, and by far not least, we have failed to actively involve the people who build the technology in a meaningful way, technologists; and very particularly programers.

\


Ask yourself: how to ensure a competent compliance of tech regulations and protections in a way that is safe and trustworthy for citizens if it is not transparently embedded into the technology itself and guarded by the very people who built it?

\
\
\
\


We need to break this wheel and build a new one. One in which technology is driven by Rights, where legislation defines policies covering those objectives and technical standards covering their implementation. All this in a way that technologists can not only understand but, most importantly, get behind of and actively support.

\


Whose policies you may ask?&#x20;

The governments’. For all their faults, they are the only entities that have any resemblance of accountability towards citizens. Good luck voting the next CEO in Alphabet or Meta.

\


To achieve this, we need to upgrade the existing technology paradigm, starting by accepting that _we are our data and our data is ourselves_.

\


We also need to inspire all technologists, present and future, to embrace their role as NextGen Rights Defenders and to do that the first step is to speak to them in terms they understand. As things stand, there is no technical language (i.e. taxonomies) to describe Digital Harms nor Digital Rights from a Data-Centric perspective. Without this, they won’t be able to connect the dots between what they build and its impact in digital societies; language is what allows us to define exactly what we are trying to achieve.

\


Next step would be to integrate this knowledge in their educational pipeline, enabling devs to shift the current paradigm in the hope that this, eventually, reaches the very Open Standards Working Groups that define our global technology. The interesting consequence would be that not only technology could potentially unite in the effort to protect citizens by design but that a ripple effect would arise as governments adopt those standards as templates for their own jurisdictions.

\


Needless to say, there’s plenty more to do such as creating the corresponding compliance agencies or finding venues to give birth to a new generation of very necessary tech NGOs, among many other things. One step at a time.

\
\


Fixing this is going to be a long, relentless process so the question is whether there is political will to do so or not.&#x20;

\


Governments need to take the lead to achieve _digital societies_ that are Rights-oriented by design; it’s in the name. They are organizations of people that have the legitimacy to do so and, incidentally, the only ones that have been able to produce democratic systems with proper mechanisms of accountability.&#x20;

\


Quickly glancing at the global current state of affairs, it has been a common analysis lens to divide populations between the concepts of Global North and Global South, a Us vs Them strategy that has worked so well in… well, never. Responding to inherent tribal circuitries when designing our algorithms is inevitably going to pit those technologies one against another. Talk about unconscious biases.

\


The upside? Technology may, for once, offer a solution for this: maybe the response is to observe the minimum common denominators among all of us, regardless of where we are located in the world, and ensure that our technology protects us all equally on those grounds.

\


In a world where divisions are on the rise with arbitrary dimensions of race, sex, gender and others, we must remind ourselves that machines do not understand either of these. Nor borders. Nor culture, for that matter. How am I to expect any of my digital twins to be protected across platforms if they don’t speak among themselves in the same terms?

\


Technology brings opportunities to erase those maniqueistic concepts that keep dividing us and enjoy for a change a more just interaction between humans.

\


Because for a machine we are nothing but data. And data has none of the dimensions we can’t seem to stop obsessing about.

\
\


_For a long time now, I badly wanted to watch the news on my TV at night. Then it occurred to me: I run a news division._

_\[...]_

_You know what, kiddo? In the old days of about 10 minutes ago, we did the news well. You know how? We just decided to._

Charlie Skinner - The Newsroom

\
\


Jean F. Queralt

The IO Foundation

